{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Libraries:\n",
    "For the training of Word2Vec,i will be using Gensim.It is a widely used library for NLP works.\n",
    "\n",
    "Gensim is an open-source library for unsupervised topic modeling and natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import glob\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from time import time \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bangla-stemmer in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (1.0)\n"
     ]
    }
   ],
   "source": [
    "#turn on internet option in kernel\n",
    "!pip install bangla-stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bangla_stemmer.stemmer import stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_to_word_list(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def replace_strings(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\u00C0-\\u017F\"          #latin\n",
    "                           u\"\\u2000-\\u206F\"          #generalPunctuations\n",
    "                               \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    english_pattern=re.compile('[a-zA-Z0-9]+', flags=re.I)\n",
    "    #latin_pattern=re.compile('[A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00f6\\u00f8-\\u00ff\\s]*',)\n",
    "    \n",
    "    text=emoji_pattern.sub(r'', text)\n",
    "    text=english_pattern.sub(r'', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def stopwordRemoval(text):    \n",
    "    x=str(text)\n",
    "    l=x.split()\n",
    "\n",
    "    stm=[elem for elem in l if elem not in stop]\n",
    "    \n",
    "    out=' '.join(stm)\n",
    "    \n",
    "    return str(out)\n",
    "\n",
    "def remove_punctuations(my_str):\n",
    "    # define punctuation\n",
    "    punctuations = '''```\u0012\u0010\u0002\b`\u0007\b£|¢|\u0007Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।!()-[]{};:'\"“\\’,<>./?@#$%^&*_~‘—॥”‰⚽️✌�￰৷￰'''\n",
    "    \n",
    "    no_punct = \"\"\n",
    "    for char in my_str:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "\n",
    "    # display the unpunctuated string\n",
    "    return no_punct\n",
    "\n",
    "\n",
    "\n",
    "def joining(text):\n",
    "    out=' '.join(text)\n",
    "    return out\n",
    "\n",
    "def preprocessing(text):\n",
    "    out=remove_punctuations(replace_strings(text))\n",
    "    return out\n",
    "\n",
    "\n",
    "def Stemming(text):\n",
    "    \n",
    "    x=str(text)\n",
    "    l=x.split()\n",
    "\n",
    "    stmr = stemmer.BanglaStemmer()\n",
    "    stm = stmr.stem(l)\n",
    "\n",
    "    out=' '.join(stm)\n",
    "    \n",
    "    return str(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets are loaded here:\n",
    "The datasets are the corpus and the stopwordslist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('main_dataset_v3.csv')\n",
    "data1 =pd.read_excel('stopwords_bangla.xlsx')\n",
    "stop = data1['words'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have only taken the sentences which are only in limited range if 100 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step of preprocessing,I have cleaned the datase from unnecessary things with my predefined function Preprocessing()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df.Sentence.apply(lambda x: preprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i have applied Stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Sentence'] = df.Sentence.apply(lambda x: Stemming(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords removal function is applied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df.Sentence.apply(lambda x: stopwordRemoval(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram is plotted here to visualize the dataset characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed sentences are converted into wordlist as the word2vec requiers word list for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df.Sentence.apply(lambda x: text_to_word_list(str(x)))\n",
    "word2vecinput = [row for row in df.Sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Word2Vec(word2vecinput,window=20,min_count=5,sg=0,negative=3,workers=multiprocessing.cpu_count()-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model from the file\n",
    "model = Word2Vec.load(\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that our trained Word2vec embeddings is well trained.As we can see from examples,it can predict the similar words pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('মাকে', 0.8262583017349243), ('বাবা', 0.823793351650238), ('মাবাবা', 0.8149698376655579), ('স্বামীর', 0.8085119128227234), ('মেয়েকে', 0.8040454387664795)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"মা\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from flask) (2.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from flask) (8.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.0 in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: colorama in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\6th semester\\data science lab\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('বরিশাল', 0.9098139405250549), ('সিলেট', 0.8930426239967346), ('রাজশাহী', 0.863511323928833), ('রংপুর', 0.8353511095046997), ('রাজশাহীর', 0.8289179801940918)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"খুলনা\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/get_similarity', methods=['POST'])\n",
    "def get_similarity():\n",
    "    if request.method == 'POST':\n",
    "        word = request.form['word']\n",
    "        similar_words = model.wv.most_similar(word, topn=5)\n",
    "        return render_template('result.html', word=word, similar_words=similar_words)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('সিয়াম', 0.8883941769599915), ('রোজা', 0.883510410785675), ('উপবাস', 0.8675622940063477), ('মাহে', 0.82308030128479), ('সংযম', 0.7846404314041138)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"রোজা\", topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(render_template('index.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('অপরাধের', 0.8259578347206116), ('অপরাধে', 0.7584247589111328), ('অপরাধগুলোর', 0.7536808848381042), ('ফৌজদারি', 0.7304179072380066), ('অপরাধীদের', 0.7231983542442322)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"অপরাধ\", topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the function compute cosine similarity between two words.We can see that words are very similar as the value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
